{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장 구조형태 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/opt/ml/input/data\"\n",
    "anns_file_path = dataset_path + \"/train_all.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "    \n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dataset['info']\n",
    "licenses = dataset['licenses']\n",
    "images = dataset['images']\n",
    "categories = dataset['categories']\n",
    "annotations = dataset['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(info))\n",
    "print(type(licenses))\n",
    "print(type(images))\n",
    "print(type(categories))\n",
    "print(type(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"category count : \", len(categories))\n",
    "print(\"images count : \", len(images))\n",
    "print(\"annotations count : \", len(annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 카테고리의 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cats = len(categories)\n",
    "nr_annotations = len(annotations)\n",
    "nr_images = len(images)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_histogram = np.zeros(nr_cats, dtype = int)\n",
    "\n",
    "for ann in annotations:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 당 object 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "image_segmentation = defaultdict(int)\n",
    "\n",
    "for annotation in annotations:\n",
    "    image_id = annotation[\"image_id\"]\n",
    "    image_segmentation[image_id] += len(annotation['segmentation'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(image_segmentation.values())) # 최대 segment개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_length\n",
    "image_segmentation_count = np.zeros(8, dtype = int)\n",
    "image_segmentation_count_label = np.array(['0 ~ 3','3 ~ 5', '5 ~ 10','10 ~ 30', '30 ~ 60', '60 ~ 90', '90 ~ 120', '120 ~'])\n",
    "\n",
    "for k,v in image_segmentation.items():\n",
    "    if v>= 0 and v < 3:\n",
    "        image_segmentation_count[0] += 1\n",
    "    elif v>= 3 and v < 5:\n",
    "        image_segmentation_count[1] += 1\n",
    "    elif v>= 5 and v < 10:\n",
    "        image_segmentation_count[2] += 1\n",
    "    elif v>= 10 and v < 30:\n",
    "        image_segmentation_count[3] += 1\n",
    "    elif v>= 30 and v < 60:\n",
    "        image_segmentation_count[4] += 1\n",
    "    elif v>= 60 and v < 90:\n",
    "        image_segmentation_count[5] += 1\n",
    "    elif v>= 90 and v < 120:\n",
    "        image_segmentation_count[6] += 1\n",
    "    elif v>= 120:\n",
    "        image_segmentation_count[7] += 1\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'include segment': image_segmentation_count_label, 'count': image_segmentation_count})\n",
    "df = df.sort_values('count', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"count\", y=\"include segment\", data=df, label=\"Total\", color=\"b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 마스킹 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/ml/pstage3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0 # 픽셀 정규화 과정 - 추후 test set기준으로 정규화 작업 진행\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train_all.json'\n",
    "\n",
    "# batch size를 위한 함수\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "        A.GridDistortion(p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
    "        ], p=0.8),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.8),    \n",
    "    A.RandomGamma(p=0.8),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=8,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세부사항 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images_info, temp_images, temp_masks, title = 'Segment image'):\n",
    "    fig, axs = plt.subplots(nrows=len(temp_images) // 2, ncols=4, figsize=(20, 20))\n",
    "    \n",
    "    for check in range(len(temp_masks)):\n",
    "        print(\"picture : \", check)\n",
    "        print('Unique values, category of transformed mask : \\n', \n",
    "              [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[check]))]\n",
    "             )\n",
    "        print(\"=======================================================\\n\")\n",
    "\n",
    "    for i in range(len(temp_images) // 2):\n",
    "        axs[i][0].imshow(temp_images[i*2].permute([1,2,0]))\n",
    "        axs[i][0].grid(False)\n",
    "        axs[i][0].set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 12)\n",
    "        axs[i][0].axis('off')\n",
    "\n",
    "        axs[i][1].imshow(temp_masks[i*2])\n",
    "        axs[i][1].grid(False)\n",
    "        axs[i][1].set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 12)\n",
    "        axs[i][1].axis('off')\n",
    "        \n",
    "        axs[i][2].imshow(temp_images[i*2+1].permute([1,2,0]))\n",
    "        axs[i][2].grid(False)\n",
    "        axs[i][2].set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 12)\n",
    "        axs[i][2].axis('off')\n",
    "\n",
    "        axs[i][3].imshow(temp_masks[i*2+1])\n",
    "        axs[i][3].grid(False)\n",
    "        axs[i][3].set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 12)\n",
    "        axs[i][3].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "show_images(image_infos, temp_images, temp_masks)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_masks[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카테고리별 표시 색(vmin, vmax으로 추후 해결) -> 결과 분석 시각화 파일에서 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_value = category_names.index('Glass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_value_dict = {}\n",
    "\n",
    "for name in category_names:\n",
    "    pixel_value_dict[name] = category_names.index(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(pixel_value_dict.keys())\n",
    "\n",
    "fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(12, 12))\n",
    "\n",
    "check_color = np.zeros((1300,1300))\n",
    "\n",
    "for i in range(13):\n",
    "    pixel_value = torch.tensor(i)\n",
    "    for i in range(100 * i, 100 * (i+1)):\n",
    "        check_color[i].fill(pixel_value)\n",
    "        \n",
    "ax1.imshow(torch.tensor(check_color))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"Class color\", fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((200,200),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.fill(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
