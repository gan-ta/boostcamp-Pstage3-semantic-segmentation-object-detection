{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get remove cython\n",
    "# !pip install -U cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update -y\n",
    "# !apt-get install --reinstall build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        paths = os.path.join(dataset_path, image_infos['file_name'])\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "#         images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.uint8)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return paths,images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return paths, images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = dataset_path + '/train_all.json'\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = []\n",
    "\n",
    "for step, (paths,images, masks, _) in enumerate(train_loader):\n",
    "    img_dir.append(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "print(img_dir[0])\n",
    "\n",
    "Image.open(img_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = dataset_path + '/train_all.json'\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    Normalize(\n",
    "        mean=(0.46009655,0.43957878,0.41827092), \n",
    "        std=(0.2108204,0.20766491,0.21656131), \n",
    "        max_pixel_value=255.0, \n",
    "        p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=8,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for _,imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = temp_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = temp_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.uint8(255 * img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.random.rand(8,12,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "MAX_ITER = 10\n",
    "\n",
    "POS_W = 3\n",
    "POS_XY_STD = 1\n",
    "Bi_W = 4\n",
    "Bi_XY_STD = 67\n",
    "Bi_RGB_STD = 3\n",
    "\n",
    "#Bi_W=4\n",
    "#Bi_XY_STD=49\n",
    "#Bi_RGB_STD=5\n",
    "\n",
    "#POS_W=3\n",
    "#POS_XY_STD=3\n",
    "\n",
    "def dense_crf(t_img, t_output_probs):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(t_img)):\n",
    "        img = t_img[i].numpy()\n",
    "        img = np.uint8(255 * img)\n",
    "        \n",
    "        output_probs = t_output_probs[i]\n",
    "        \n",
    "        c = output_probs.shape[0]\n",
    "        h = output_probs.shape[1]\n",
    "        w = output_probs.shape[2]\n",
    "\n",
    "        U = utils.unary_from_softmax(output_probs)\n",
    "        U = np.ascontiguousarray(U)\n",
    "\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        d = dcrf.DenseCRF2D(w, h, c)\n",
    "        d.setUnaryEnergy(U)\n",
    "        d.addPairwiseGaussian(sxy=POS_XY_STD, compat=POS_W)\n",
    "        d.addPairwiseBilateral(sxy=Bi_XY_STD, srgb=Bi_RGB_STD, rgbim=img.reshape(512,512,3), compat=Bi_W)\n",
    "\n",
    "        Q = d.inference(MAX_ITER)\n",
    "        Q = np.array(Q).reshape((c, h, w))\n",
    "        res.append(Q)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "MAX_ITER = 10\n",
    "\n",
    "POS_W = 3\n",
    "POS_XY_STD = 1\n",
    "Bi_W = 4\n",
    "Bi_XY_STD = 67\n",
    "Bi_RGB_STD = 3\n",
    "\n",
    "#Bi_W=4\n",
    "#Bi_XY_STD=49\n",
    "#Bi_RGB_STD=5\n",
    "\n",
    "#POS_W=3\n",
    "#POS_XY_STD=3\n",
    "\n",
    "def dense_crf(t_img, t_output_probs):\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(len(t_img))):\n",
    "        img = t_img[i].numpy()\n",
    "        img = np.uint8(255 * img)\n",
    "        \n",
    "        output_probs = t_output_probs[i]\n",
    "        \n",
    "        c = output_probs.shape[0]\n",
    "        h = output_probs.shape[1]\n",
    "        w = output_probs.shape[2]\n",
    "\n",
    "        U = utils.unary_from_softmax(output_probs)\n",
    "        U = np.ascontiguousarray(U)\n",
    "\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        d = dcrf.DenseCRF2D(w, h, c)\n",
    "        d.setUnaryEnergy(U)\n",
    "        d.addPairwiseGaussian(sxy=POS_XY_STD, compat=POS_W)\n",
    "        d.addPairwiseBilateral(sxy=Bi_XY_STD, srgb=Bi_RGB_STD, rgbim=img.reshape(512,512,3), compat=Bi_W)\n",
    "\n",
    "        Q = d.inference(MAX_ITER)\n",
    "        Q = np.array(Q).reshape((c, h, w))\n",
    "        res.append(Q)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = dense_crf(img,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dense_crf(img, output_probs):\n",
    "#     c = output_probs.shape[0]\n",
    "#     h = output_probs.shape[1]\n",
    "#     w = output_probs.shape[2]\n",
    "\n",
    "#     U = utils.unary_from_softmax(output_probs)\n",
    "#     U = np.ascontiguousarray(U)\n",
    "\n",
    "#     img = np.ascontiguousarray(img)\n",
    "\n",
    "#     d = dcrf.DenseCRF2D(w, h, c)\n",
    "#     d.setUnaryEnergy(U)\n",
    "#     d.addPairwiseGaussian(sxy=POS_XY_STD, compat=POS_W)\n",
    "#     d.addPairwiseBilateral(sxy=Bi_XY_STD, srgb=Bi_RGB_STD, rgbim=img, compat=Bi_W)\n",
    "\n",
    "#     Q = d.inference(MAX_ITER)\n",
    "#     Q = np.array(Q).reshape((c, h, w))\n",
    "#     return Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
