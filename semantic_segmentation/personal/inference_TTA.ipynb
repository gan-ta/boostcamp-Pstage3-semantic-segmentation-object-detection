{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "def __get_logger():\n",
    "    \"\"\"로거 인스턴스 반환\n",
    "    \"\"\"\n",
    "\n",
    "    __logger = logging.getLogger('logger')\n",
    "\n",
    "    # # 로그 포멧 정의\n",
    "    formatter = logging.Formatter(fmt=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "    # 스트림 핸들러 정의\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    # 각 핸들러에 포멧 지정\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    # 로거 인스턴스에 핸들러 삽입\n",
    "    __logger.addHandler(stream_handler)\n",
    "    # 로그 레벨 정의\n",
    "    __logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    return __logger\n",
    "\n",
    "logger = __get_logger()\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    \"\"\"저장된 model에 대한 prediction 수행\n",
    "\n",
    "    Args:\n",
    "        model(nn.Module) : 저장된 모델\n",
    "        test_loader(Dataloader) : test데이터의 dataloader\n",
    "        device\n",
    "\n",
    "    테스트 loader는 배치 사이즈 4 이하이면 작동을 하지 않습니다.   \n",
    "    \"\"\"\n",
    "\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "\n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs1,imgs2, image_infos) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs1 = model(torch.stack(imgs1).to(device))\n",
    "            outs2 = model(torch.stack(imgs2).to(device))\n",
    "            outs = (outs1 + outs2) / 2\n",
    "            \n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img1,img2, mask in zip(np.stack(imgs1), np.stack(imgs2),oms):\n",
    "                transformed = transform(image=img1, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "\n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "\n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "\n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    logger.info(\"*************************************\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    logger.info(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    logger.info(f'We will use the GPU:{torch.cuda.get_device_name(0)}')\n",
    "    logger.info(\"*************************************\\n\")\n",
    "else:\n",
    "    logger.info(\"*************************************\")\n",
    "    logger.info('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    logger.info(\"*************************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "\n",
    "def data_eda():\n",
    "    \"\"\"데이터 eda 및 학습 데이터에 필요한 데이터 프레임 가져오기 \n",
    "\n",
    "    Returns:\n",
    "        sorted_df(DataFrame) : 로드 시 필요정보를 가지는 데이터프레임 반환\n",
    "    \"\"\"\n",
    "\n",
    "    anns_file_path = dataset_path + '/' + 'train.json'\n",
    "    \n",
    "    # Read annotations\n",
    "    with open(anns_file_path, 'r') as f:\n",
    "        dataset = json.loads(f.read())\n",
    "        \n",
    "    categories = dataset['categories']\n",
    "    anns = dataset['annotations']\n",
    "    imgs = dataset['images']\n",
    "    nr_cats = len(categories)\n",
    "    nr_annotations = len(anns)\n",
    "    nr_images = len(imgs)\n",
    "    \n",
    "    # Load categories and super categories\n",
    "    cat_names = []\n",
    "    super_cat_names = []\n",
    "    super_cat_ids = {}\n",
    "    super_cat_last_name = ''\n",
    "    nr_super_cats = 0\n",
    "    \n",
    "    for cat_it in categories:\n",
    "        cat_names.append(cat_it['name'])\n",
    "        super_cat_name = cat_it['supercategory']\n",
    "        \n",
    "        # Adding new supercat\n",
    "        if super_cat_name != super_cat_last_name:\n",
    "            super_cat_names.append(super_cat_name)\n",
    "            super_cat_ids[super_cat_name] = nr_super_cats\n",
    "            super_cat_last_name = super_cat_name\n",
    "            nr_super_cats += 1\n",
    "            \n",
    "    cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "    for ann in anns:\n",
    "        cat_histogram[ann['category_id']] += 1\n",
    "        \n",
    "    # # Initialize the matplotlib figure\n",
    "    # f, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "    df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "    # category labeling \n",
    "    sorted_temp_df = df.sort_index()\n",
    "    \n",
    "    # background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "    sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "    sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\" dataloader의 정의\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform1 = None, transform2 = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "        self.coco = COCO(data_dir)\n",
    "        sorted_df = data_eda()\n",
    "        self.category_names = list(sorted_df.Categories)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        paths = os.path.join(dataset_path, image_infos['file_name'])\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "        # images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = self.category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            # masks = masks.astype(np.float32)\n",
    "            masks = masks.astype(np.uint8)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform1 is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return paths, images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform1 is not None:\n",
    "                transformed1 = self.transform1(image=images)\n",
    "                images1 = transformed1[\"image\"]\n",
    "            if self.transform2 is not None:\n",
    "                transformed2 = self.transform2(image=images)\n",
    "                images2 = transformed2[\"image\"]\n",
    "            \n",
    "            return images1,images2, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 갈아 끼우기\n",
    "model_path = '/opt/ml/saved/check.pt' \n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "        encoder_name=\"resnext50_32x4d\",\n",
    "        encoder_weights= \"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=12\n",
    "        )\n",
    "# model = ResNextDeepLabV3AllTrain()\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "test_transform1 = A.Compose([\n",
    "    A.Normalize(\n",
    "                 mean=(0.46446795,0.44277694,0.42146815), \n",
    "                 std=(0.21137457,0.20805008,0.21553354), \n",
    "                 max_pixel_value=255.0, \n",
    "                 p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform2 = A.Compose([\n",
    "    A.CLAHE(p = 1.0),\n",
    "    A.Normalize(\n",
    "                 mean=(0.46446795,0.44277694,0.42146815), \n",
    "                 std=(0.21137457,0.20805008,0.21553354), \n",
    "                 max_pixel_value=255.0, \n",
    "                 p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, \n",
    "                                mode='test', \n",
    "                                transform1=test_transform1,\n",
    "                                transform2=test_transform2\n",
    "                               )\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "batch_size= 8,\n",
    "num_workers=2,\n",
    "collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('/opt/ml/submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"/opt/ml/submission/\" + \"check\" + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([2, 3, 512, 512])\n",
    "y = torch.randn([2, 3, 512, 512])\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
